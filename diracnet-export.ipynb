{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DiracNets\n",
    "========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we provide DiracNet-18-0.75 (12.8M parameters) model definitions with pretrained weights.\n",
    "The model was trained using functional API of PyTorch on ILSVRC2012 train set.\n",
    "\n",
    "top-1 and top-5 errors on ILSVRC2012 validation set:\n",
    "**32.29, 12.16**\n",
    "\n",
    "We saved the weights in hdf5 format, so that they can be loaded in other frameworks\n",
    "without PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import hickle as hkl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch normalization and dirac parameterization folded into convolutional filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv.bias (48,)\n",
      "conv.weight (48, 3, 7, 7)\n",
      "fc.bias (1000,)\n",
      "fc.weight (1000, 384)\n",
      "group0.block0.conv.bias (48,)\n",
      "group0.block0.conv.weight (48, 96, 3, 3)\n",
      "group0.block1.conv.bias (48,)\n",
      "group0.block1.conv.weight (48, 96, 3, 3)\n",
      "group0.block2.conv.bias (48,)\n",
      "group0.block2.conv.weight (48, 96, 3, 3)\n",
      "group0.block3.conv.bias (48,)\n",
      "group0.block3.conv.weight (48, 96, 3, 3)\n",
      "group1.block0.conv.bias (96,)\n",
      "group1.block0.conv.weight (96, 96, 3, 3)\n",
      "group1.block1.conv.bias (96,)\n",
      "group1.block1.conv.weight (96, 192, 3, 3)\n",
      "group1.block2.conv.bias (96,)\n",
      "group1.block2.conv.weight (96, 192, 3, 3)\n",
      "group1.block3.conv.bias (96,)\n",
      "group1.block3.conv.weight (96, 192, 3, 3)\n",
      "group2.block0.conv.bias (192,)\n",
      "group2.block0.conv.weight (192, 192, 3, 3)\n",
      "group2.block1.conv.bias (192,)\n",
      "group2.block1.conv.weight (192, 384, 3, 3)\n",
      "group2.block2.conv.bias (192,)\n",
      "group2.block2.conv.weight (192, 384, 3, 3)\n",
      "group2.block3.conv.bias (192,)\n",
      "group2.block3.conv.weight (192, 384, 3, 3)\n",
      "group3.block0.conv.bias (384,)\n",
      "group3.block0.conv.weight (384, 384, 3, 3)\n",
      "group3.block1.conv.bias (384,)\n",
      "group3.block1.conv.weight (384, 768, 3, 3)\n",
      "group3.block2.conv.bias (384,)\n",
      "group3.block2.conv.weight (384, 768, 3, 3)\n",
      "group3.block3.conv.bias (384,)\n",
      "group3.block3.conv.weight (384, 768, 3, 3)\n",
      "\n",
      "Total parameters: 12753640\n"
     ]
    }
   ],
   "source": [
    "params = hkl.load('./diracnet-18-0.75-br-export.hkl')\n",
    "\n",
    "# convert numpy arrays to torch Variables\n",
    "for k,v in sorted(params.items()):\n",
    "    print k, v.shape\n",
    "    params[k] = Variable(torch.from_numpy(v), requires_grad=True)\n",
    "    \n",
    "print '\\nTotal parameters:', sum(v.numel() for v in params.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_diracnet(depth):\n",
    "    definitions = {18: [2,2,2,2], 34: [3,4,6,5]}\n",
    "    blocks = definitions[depth]\n",
    "    \n",
    "    def ncrelu(x):\n",
    "        return torch.cat([x.clamp(min=0), x.clamp(max=0)], dim=1)\n",
    "\n",
    "    def group(o, params, base, count):\n",
    "        for i in range(count):\n",
    "            o = F.conv2d(ncrelu(o), padding=1,\n",
    "                         weight=params['%s.block%d.conv.weight' % (base, i)],\n",
    "                         bias=params['%s.block%d.conv.bias' % (base, i)])\n",
    "        return o\n",
    "    \n",
    "    def f(inputs, params):\n",
    "        o = F.conv2d(inputs, params['conv.weight'], params['conv.bias'], padding=3, stride=2)\n",
    "        o = F.max_pool2d(o, 3, 2, 1)\n",
    "        o = group(o, params, 'group0', blocks[0] * 2)\n",
    "        o = F.max_pool2d(o, 2)\n",
    "        o = group(o, params, 'group1', blocks[1] * 2)\n",
    "        o = F.max_pool2d(o, 2)\n",
    "        o = group(o, params, 'group2', blocks[2] * 2)\n",
    "        o = F.max_pool2d(o, 2)\n",
    "        o = group(o, params, 'group3', blocks[3] * 2)\n",
    "        o = F.avg_pool2d(F.relu(o), o.size(-1))\n",
    "        o = F.linear(o.view(o.size(0), -1), params['fc.weight'], params['fc.bias'])\n",
    "        return o\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.3973  1.1641 -0.9560  ...   0.1217 -0.5293  1.5345\n",
      "[torch.FloatTensor of size 1x1000]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn(1,3,224,224)\n",
    "y = define_diracnet(18)(Variable(inputs), params)\n",
    "print y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# ugh modules are annoying\n",
    "\n",
    "class NCReLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.cat([x.clamp(min=0), x.clamp(max=0)], dim=1)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'NCReLU()'\n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'Flatten()'\n",
    "\n",
    "    \n",
    "model = nn.Sequential()\n",
    "model.add_module('conv', nn.Conv2d(3, 48, kernel_size=7, stride=2, padding=3))\n",
    "model.add_module('max_pool0', nn.MaxPool2d(3, 2, 1))\n",
    "for i in range(4):\n",
    "    model.add_module('group0.block%d.ncrelu' % i, NCReLU())\n",
    "    model.add_module('group0.block%d.conv' % i, nn.Conv2d(96, 48, kernel_size=3, padding=1))\n",
    "model.add_module('max_pool1', nn.MaxPool2d(2))\n",
    "for i in range(4):\n",
    "    model.add_module('group1.block%d.ncrelu' % i, NCReLU())\n",
    "    model.add_module('group1.block%d.conv' % i, nn.Conv2d(96 if i==0 else 192, 96, kernel_size=3, padding=1))\n",
    "model.add_module('max_pool2', nn.MaxPool2d(2))\n",
    "for i in range(4):\n",
    "    model.add_module('group2.block%d.ncrelu' % i, NCReLU())\n",
    "    model.add_module('group2.block%d.conv' % i, nn.Conv2d(192 if i==0 else 384, 192, kernel_size=3, padding=1))\n",
    "model.add_module('max_pool3', nn.MaxPool2d(2))\n",
    "for i in range(4):\n",
    "    model.add_module('group3.block%d.ncrelu' % i, NCReLU())\n",
    "    model.add_module('group3.block%d.conv' % i, nn.Conv2d(384 if i==0 else 768, 384, kernel_size=3, padding=1))\n",
    "model.add_module('relu', nn.ReLU())\n",
    "model.add_module('avg_pool', nn.AvgPool2d(7))\n",
    "model.add_module('view', Flatten())\n",
    "model.add_module('fc', nn.Linear(in_features=384, out_features=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_state_dict({k: v.data for k,v in params.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check against functional model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9073486328125e-06"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(inputs)\n",
    "(model(x) - define_diracnet(18)(x, params)).abs().sum().data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential (\n",
      "  (conv): Conv2d(3, 48, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "  (max_pool0): MaxPool2d (size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1))\n",
      "  (group0.block0.ncrelu): NCReLU()\n",
      "  (group0.block0.conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (group0.block1.ncrelu): NCReLU()\n",
      "  (group0.block1.conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (group0.block2.ncrelu): NCReLU()\n",
      "  (group0.block2.conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (group0.block3.ncrelu): NCReLU()\n",
      "  (group0.block3.conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (max_pool1): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (group1.block0.ncrelu): NCReLU()\n",
      "  (group1.block0.conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (group1.block1.ncrelu): NCReLU()\n",
      "  (group1.block1.conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (group1.block2.ncrelu): NCReLU()\n",
      "  (group1.block2.conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (group1.block3.ncrelu): NCReLU()\n",
      "  (group1.block3.conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (max_pool2): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (group2.block0.ncrelu): NCReLU()\n",
      "  (group2.block0.conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (group2.block1.ncrelu): NCReLU()\n",
      "  (group2.block1.conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (group2.block2.ncrelu): NCReLU()\n",
      "  (group2.block2.conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (group2.block3.ncrelu): NCReLU()\n",
      "  (group2.block3.conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (max_pool3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (group3.block0.ncrelu): NCReLU()\n",
      "  (group3.block0.conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (group3.block1.ncrelu): NCReLU()\n",
      "  (group3.block1.conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (group3.block2.ncrelu): NCReLU()\n",
      "  (group3.block2.conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (group3.block3.ncrelu): NCReLU()\n",
      "  (group3.block3.conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu): ReLU ()\n",
      "  (avg_pool): AvgPool2d (\n",
      "  )\n",
      "  (view): Flatten()\n",
      "  (fc): Linear (384 -> 1000)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Original definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_train_diracnet(depth):\n",
    "    definitions = {18: [2,2,2,2], 34: [3,4,6,5]}\n",
    "    blocks = definitions[depth]\n",
    "    \n",
    "    def ncrelu(x):\n",
    "        return torch.cat([x.clamp(min=0), x.clamp(max=0)], dim=1)\n",
    "    \n",
    "    def batch_norm(x, params, stats, base, mode):\n",
    "        return F.batch_norm(x, weight=params[base + '.weight'],\n",
    "                            bias=params[base + '.bias'],\n",
    "                            running_mean=stats[base + '.running_mean'],\n",
    "                            running_var=stats[base + '.running_var'],\n",
    "                            training=mode)\n",
    "\n",
    "    def block(o, params, stats, base, mode, j):\n",
    "        name = '%s.conv' % base\n",
    "        w = params[name]\n",
    "        gamma = params[name + '.gamma'].expand_as(w)\n",
    "        beta = params[name + '.beta'].view(-1,1,1,1).expand_as(w)\n",
    "        eye = Variable(stats['eye' + '_'.join(map(str, w.size()))])\n",
    "        w = beta * F.normalize(w.view(w.size(0), -1)).view_as(w) + gamma * eye\n",
    "        o = F.conv2d(ncrelu(o), w, stride=1, padding=1)\n",
    "        o = batch_norm(o, params, stats, '%s.bn' % base, mode)\n",
    "        return o\n",
    "\n",
    "    def group(o, params, stats, base, mode, count):\n",
    "        for i in range(count):\n",
    "            o = block(o, params, stats, '%s.block%d' % (base, i), mode, i)\n",
    "        return o\n",
    "\n",
    "    def f(inputs, params, stats, mode):\n",
    "        o = F.conv2d(inputs, params['conv'], padding=3, stride=2)\n",
    "        o = batch_norm(o, params, stats, 'bn', mode)\n",
    "        o = F.max_pool2d(o, 3, 2, 1)\n",
    "        o = group(o, params, stats, 'group0', mode, blocks[0] * 2)\n",
    "        o = F.max_pool2d(o, 2)\n",
    "        o = group(o, params, stats, 'group1', mode, blocks[1] * 2)\n",
    "        o = F.max_pool2d(o, 2)\n",
    "        o = group(o, params, stats, 'group2', mode, blocks[2] * 2)\n",
    "        o = F.max_pool2d(o, 2)\n",
    "        o = group(o, params, stats, 'group3', mode, blocks[3] * 2)\n",
    "        o = F.avg_pool2d(F.relu(o), o.size(-1))\n",
    "        o = o.view(o.size(0), -1)\n",
    "        o = F.linear(o, params['fc.weight'], params['fc.bias'])\n",
    "        return o\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn.bias (48,)\n",
      "bn.weight (48,)\n",
      "conv (48, 3, 7, 7)\n",
      "fc.bias (1000,)\n",
      "fc.weight (1000, 384)\n",
      "group0.block0.bn.bias (48,)\n",
      "group0.block0.bn.weight (48,)\n",
      "group0.block0.conv (48, 96, 3, 3)\n",
      "group0.block0.conv.beta (48,)\n",
      "group0.block0.conv.gamma (1,)\n",
      "group0.block1.bn.bias (48,)\n",
      "group0.block1.bn.weight (48,)\n",
      "group0.block1.conv (48, 96, 3, 3)\n",
      "group0.block1.conv.beta (48,)\n",
      "group0.block1.conv.gamma (1,)\n",
      "group0.block2.bn.bias (48,)\n",
      "group0.block2.bn.weight (48,)\n",
      "group0.block2.conv (48, 96, 3, 3)\n",
      "group0.block2.conv.beta (48,)\n",
      "group0.block2.conv.gamma (1,)\n",
      "group0.block3.bn.bias (48,)\n",
      "group0.block3.bn.weight (48,)\n",
      "group0.block3.conv (48, 96, 3, 3)\n",
      "group0.block3.conv.beta (48,)\n",
      "group0.block3.conv.gamma (1,)\n",
      "group1.block0.bn.bias (96,)\n",
      "group1.block0.bn.weight (96,)\n",
      "group1.block0.conv (96, 96, 3, 3)\n",
      "group1.block0.conv.beta (96,)\n",
      "group1.block0.conv.gamma (1,)\n",
      "group1.block1.bn.bias (96,)\n",
      "group1.block1.bn.weight (96,)\n",
      "group1.block1.conv (96, 192, 3, 3)\n",
      "group1.block1.conv.beta (96,)\n",
      "group1.block1.conv.gamma (1,)\n",
      "group1.block2.bn.bias (96,)\n",
      "group1.block2.bn.weight (96,)\n",
      "group1.block2.conv (96, 192, 3, 3)\n",
      "group1.block2.conv.beta (96,)\n",
      "group1.block2.conv.gamma (1,)\n",
      "group1.block3.bn.bias (96,)\n",
      "group1.block3.bn.weight (96,)\n",
      "group1.block3.conv (96, 192, 3, 3)\n",
      "group1.block3.conv.beta (96,)\n",
      "group1.block3.conv.gamma (1,)\n",
      "group2.block0.bn.bias (192,)\n",
      "group2.block0.bn.weight (192,)\n",
      "group2.block0.conv (192, 192, 3, 3)\n",
      "group2.block0.conv.beta (192,)\n",
      "group2.block0.conv.gamma (1,)\n",
      "group2.block1.bn.bias (192,)\n",
      "group2.block1.bn.weight (192,)\n",
      "group2.block1.conv (192, 384, 3, 3)\n",
      "group2.block1.conv.beta (192,)\n",
      "group2.block1.conv.gamma (1,)\n",
      "group2.block2.bn.bias (192,)\n",
      "group2.block2.bn.weight (192,)\n",
      "group2.block2.conv (192, 384, 3, 3)\n",
      "group2.block2.conv.beta (192,)\n",
      "group2.block2.conv.gamma (1,)\n",
      "group2.block3.bn.bias (192,)\n",
      "group2.block3.bn.weight (192,)\n",
      "group2.block3.conv (192, 384, 3, 3)\n",
      "group2.block3.conv.beta (192,)\n",
      "group2.block3.conv.gamma (1,)\n",
      "group3.block0.bn.bias (384,)\n",
      "group3.block0.bn.weight (384,)\n",
      "group3.block0.conv (384, 384, 3, 3)\n",
      "group3.block0.conv.beta (384,)\n",
      "group3.block0.conv.gamma (1,)\n",
      "group3.block1.bn.bias (384,)\n",
      "group3.block1.bn.weight (384,)\n",
      "group3.block1.conv (384, 768, 3, 3)\n",
      "group3.block1.conv.beta (384,)\n",
      "group3.block1.conv.gamma (1,)\n",
      "group3.block2.bn.bias (384,)\n",
      "group3.block2.bn.weight (384,)\n",
      "group3.block2.conv (384, 768, 3, 3)\n",
      "group3.block2.conv.beta (384,)\n",
      "group3.block2.conv.gamma (1,)\n",
      "group3.block3.bn.bias (384,)\n",
      "group3.block3.bn.weight (384,)\n",
      "group3.block3.conv (384, 768, 3, 3)\n",
      "group3.block3.conv.beta (384,)\n",
      "group3.block3.conv.gamma (1,)\n",
      "\n",
      "Total parameters: 12759464\n"
     ]
    }
   ],
   "source": [
    "data = hkl.load('./diracnet-18-0.75-br.hkl')\n",
    "params = data['params']\n",
    "stats = data['stats']\n",
    "\n",
    "# convert numpy arrays to torch Variables\n",
    "for k,v in sorted(params.items()):\n",
    "    print k, v.shape\n",
    "    params[k] = Variable(torch.from_numpy(v), requires_grad=True)\n",
    "for k,v in sorted(stats.items()):\n",
    "    stats[k] = torch.from_numpy(v)\n",
    "    \n",
    "print '\\nTotal parameters:', sum(v.numel() for v in params.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.2164  1.5824 -0.9205  ...   0.5037 -0.3045  1.9326\n",
      "[torch.FloatTensor of size 1x1000]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn(1,3,224,224)\n",
    "y = define_train_diracnet(18)(Variable(inputs), params, stats, False)\n",
    "print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0019147731363773346"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(inputs)\n",
    "(model(x) - define_train_diracnet(18)(x, params, stats, False)).abs().sum().data[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
