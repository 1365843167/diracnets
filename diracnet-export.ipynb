{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DiracNets\n",
    "========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we provide DiracNet-18-0.75 (12.8M parameters) model definitions with pretrained weights.\n",
    "The model was trained using functional API of PyTorch on ILSVRC2012 train set.\n",
    "\n",
    "top-1 and top-5 errors on ILSVRC2012 validation set:\n",
    "**32.29, 12.16**\n",
    "\n",
    "We saved the weights in hdf5 format, so that they can be loaded in other frameworks\n",
    "without PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import hickle as hkl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv.weight (48, 3, 7, 7)\n",
      "fc.bias (1000,)\n",
      "fc.weight (1000, 384)\n",
      "group0.block0.bn.a (48,)\n",
      "group0.block0.bn.b (48,)\n",
      "group0.block0.conv.bias (48,)\n",
      "group0.block0.conv.weight (48, 96, 3, 3)\n",
      "group0.block1.conv.bias (48,)\n",
      "group0.block1.conv.weight (48, 96, 3, 3)\n",
      "group0.block2.conv.bias (48,)\n",
      "group0.block2.conv.weight (48, 96, 3, 3)\n",
      "group0.block3.conv.weight (48, 96, 3, 3)\n",
      "group1.block0.bn.a (48,)\n",
      "group1.block0.bn.b (48,)\n",
      "group1.block0.conv.bias (96,)\n",
      "group1.block0.conv.weight (96, 96, 3, 3)\n",
      "group1.block1.conv.bias (96,)\n",
      "group1.block1.conv.weight (96, 192, 3, 3)\n",
      "group1.block2.conv.bias (96,)\n",
      "group1.block2.conv.weight (96, 192, 3, 3)\n",
      "group1.block3.conv.weight (96, 192, 3, 3)\n",
      "group2.block0.bn.a (96,)\n",
      "group2.block0.bn.b (96,)\n",
      "group2.block0.conv.bias (192,)\n",
      "group2.block0.conv.weight (192, 192, 3, 3)\n",
      "group2.block1.conv.bias (192,)\n",
      "group2.block1.conv.weight (192, 384, 3, 3)\n",
      "group2.block2.conv.bias (192,)\n",
      "group2.block2.conv.weight (192, 384, 3, 3)\n",
      "group2.block3.conv.weight (192, 384, 3, 3)\n",
      "group3.block0.bn.a (192,)\n",
      "group3.block0.bn.b (192,)\n",
      "group3.block0.conv.bias (384,)\n",
      "group3.block0.conv.weight (384, 384, 3, 3)\n",
      "group3.block1.conv.bias (384,)\n",
      "group3.block1.conv.weight (384, 768, 3, 3)\n",
      "group3.block2.conv.bias (384,)\n",
      "group3.block2.conv.weight (384, 768, 3, 3)\n",
      "group3.block3.conv.bias (384,)\n",
      "group3.block3.conv.weight (384, 768, 3, 3)\n",
      "\n",
      "Total parameters: 12754024\n"
     ]
    }
   ],
   "source": [
    "params = hkl.load('./diracnet-18-0.75-export.hkl')\n",
    "\n",
    "# convert numpy arrays to torch Variables\n",
    "for k,v in sorted(params.items()):\n",
    "    print k, v.shape\n",
    "    params[k] = Variable(torch.from_numpy(v), requires_grad=True)\n",
    "    \n",
    "print '\\nTotal parameters:', sum(v.numel() for v in params.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_diracnet(depth):\n",
    "    definitions = {18: [2,2,2,2], 34: [3,4,6,5]}\n",
    "    blocks = definitions[depth]\n",
    "    \n",
    "    def ncrelu(x):\n",
    "        return torch.cat([x.clamp(min=0), x.clamp(max=0)], dim=1)\n",
    "\n",
    "    def group(o, params, base, count):\n",
    "        for i in range(count):\n",
    "            if i == 0:\n",
    "                s = '%s.block%d.bn' % (base, i)\n",
    "                a = params[s + '.a'].view(1,-1,1,1).expand_as(o)\n",
    "                b = params[s + '.b'].view(1,-1,1,1).expand_as(o)\n",
    "                o = o * a + b\n",
    "            s = '%s.block%d.conv' % (base, i)\n",
    "            weight = params[s + '.weight']\n",
    "            bias = params[s + '.bias'] if i < count - 1 or base == 'group3' else None\n",
    "            o = F.conv2d(ncrelu(o), weight=weight, bias=bias, padding=1)\n",
    "        return o\n",
    "    \n",
    "    def f(inputs, params):\n",
    "        o = F.conv2d(inputs, params['conv.weight'], padding=3, stride=2)\n",
    "        o = F.max_pool2d(o, 3, 2, 1)\n",
    "        o = group(o, params, 'group0', blocks[0] * 2)\n",
    "        o = F.max_pool2d(o, 2)\n",
    "        o = group(o, params, 'group1', blocks[1] * 2)\n",
    "        o = F.max_pool2d(o, 2)\n",
    "        o = group(o, params, 'group2', blocks[2] * 2)\n",
    "        o = F.max_pool2d(o, 2)\n",
    "        o = group(o, params, 'group3', blocks[3] * 2)\n",
    "        o = F.avg_pool2d(F.relu(o), o.size(-1))\n",
    "        o = o.view(o.size(0), -1)\n",
    "        o = F.linear(o, params['fc.weight'], params['fc.bias'])\n",
    "        return o\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.5105  2.4716  1.5387  ...  -0.4935  0.3081  2.4002\n",
      "[torch.FloatTensor of size 1x1000]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn(1,3,224,224)\n",
    "y = define_diracnet(18)(Variable(inputs), params)\n",
    "print y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# ugh modules are annoying\n",
    "\n",
    "class NCReLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.cat([x.clamp(min=0), x.clamp(max=0)], dim=1)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'NCReLU()'\n",
    "\n",
    "class Affine(nn.Module):\n",
    "    \n",
    "    def __init__(self, channels):\n",
    "        super(Affine, self).__init__()\n",
    "        self.a = nn.Parameter(torch.Tensor(channels))\n",
    "        self.b = nn.Parameter(torch.Tensor(channels))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        a = self.a.view(1,-1,1,1).expand_as(x)\n",
    "        b = self.b.view(1,-1,1,1).expand_as(x)\n",
    "        return x * a + b\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'Affine(%d)' % self.a.numel()\n",
    "    \n",
    "class Flatten(nn.Module):\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'Flatten()'\n",
    "\n",
    "    \n",
    "model = nn.Sequential()\n",
    "\n",
    "model.add_module('conv', nn.Conv2d(in_channels=3, out_channels=48,\n",
    "                                   kernel_size=7, stride=2, padding=3, bias=False))\n",
    "model.add_module('max_pool0', nn.MaxPool2d(3, 2, 1))\n",
    "model.add_module('group0.block0.bn', Affine(48))\n",
    "for i in range(4):\n",
    "    model.add_module('group0.block%d.ncrelu' % i, NCReLU())\n",
    "    model.add_module('group0.block%d.conv' % i, nn.Conv2d(in_channels=96, out_channels=48,\n",
    "                                                          kernel_size=3, padding=1, bias=i!=3))\n",
    "model.add_module('max_pool1', nn.MaxPool2d(2))\n",
    "model.add_module('group1.block0.bn', Affine(48))\n",
    "for i in range(4):\n",
    "    model.add_module('group1.block%d.ncrelu' % i, NCReLU())\n",
    "    model.add_module('group1.block%d.conv' % i, nn.Conv2d(in_channels=96 if i==0 else 192, out_channels=96,\n",
    "                                                          kernel_size=3, padding=1, bias=i!=3))\n",
    "model.add_module('max_pool2', nn.MaxPool2d(2))\n",
    "model.add_module('group2.block0.bn', Affine(96))\n",
    "for i in range(4):\n",
    "    model.add_module('group2.block%d.ncrelu' % i, NCReLU())\n",
    "    model.add_module('group2.block%d.conv' % i, nn.Conv2d(in_channels=192 if i==0 else 384, out_channels=192,\n",
    "                                                          kernel_size=3, padding=1, bias=i!=3))\n",
    "model.add_module('max_pool3', nn.MaxPool2d(2))\n",
    "model.add_module('group3.block0.bn', Affine(192))\n",
    "for i in range(4):\n",
    "    model.add_module('group3.block%d.ncrelu' % i, NCReLU())\n",
    "    model.add_module('group3.block%d.conv' % i, nn.Conv2d(in_channels=384 if i==0 else 768, out_channels=384,\n",
    "                                                          kernel_size=3, padding=1, bias=True))\n",
    "model.add_module('relu', nn.ReLU())\n",
    "model.add_module('avg_pool', nn.AvgPool2d(7))\n",
    "model.add_module('view', Flatten())\n",
    "model.add_module('fc', nn.Linear(in_features=384, out_features=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_state_dict({k: v.data for k,v in params.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check against functional model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(inputs)\n",
    "(model(x) - define_diracnet(18)(x, params)).abs().sum().data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential (\n",
      "  (conv): Conv2d(3, 48, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (max_pool0): MaxPool2d (size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1))\n",
      "  (group0.block0.bn): Affine(48)\n",
      "  (group0.block0.ncrelu): NCReLU()\n",
      "  (group0.block0.conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (group0.block1.ncrelu): NCReLU()\n",
      "  (group0.block1.conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (group0.block2.ncrelu): NCReLU()\n",
      "  (group0.block2.conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (group0.block3.ncrelu): NCReLU()\n",
      "  (group0.block3.conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (max_pool1): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (group1.block0.bn): Affine(48)\n",
      "  (group1.block0.ncrelu): NCReLU()\n",
      "  (group1.block0.conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (group1.block1.ncrelu): NCReLU()\n",
      "  (group1.block1.conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (group1.block2.ncrelu): NCReLU()\n",
      "  (group1.block2.conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (group1.block3.ncrelu): NCReLU()\n",
      "  (group1.block3.conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (max_pool2): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (group2.block0.bn): Affine(96)\n",
      "  (group2.block0.ncrelu): NCReLU()\n",
      "  (group2.block0.conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (group2.block1.ncrelu): NCReLU()\n",
      "  (group2.block1.conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (group2.block2.ncrelu): NCReLU()\n",
      "  (group2.block2.conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (group2.block3.ncrelu): NCReLU()\n",
      "  (group2.block3.conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (max_pool3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (group3.block0.bn): Affine(192)\n",
      "  (group3.block0.ncrelu): NCReLU()\n",
      "  (group3.block0.conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (group3.block1.ncrelu): NCReLU()\n",
      "  (group3.block1.conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (group3.block2.ncrelu): NCReLU()\n",
      "  (group3.block2.conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (group3.block3.ncrelu): NCReLU()\n",
      "  (group3.block3.conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu): ReLU ()\n",
      "  (avg_pool): AvgPool2d (\n",
      "  )\n",
      "  (view): Flatten()\n",
      "  (fc): Linear (384 -> 1000)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}